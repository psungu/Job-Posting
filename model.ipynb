{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymilvus import (Collection, CollectionSchema, DataType, FieldSchema,\n",
    "                      connections, utility)\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_jobpostings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Example job descriptions (replace with your data)\n",
    "job_descriptions = data['Job Description'].tolist()\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(str(job_descriptions), convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('job_description_embeddings.npy', 'wb') as f:\n",
    "    np.save(f, np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a collection:\n",
    "%pip install pymilvus\n",
    "from pymilvus import (Collection, CollectionSchema, DataType, FieldSchema,\n",
    "                      connections, utility)\n",
    "\n",
    "#Connects to a server:\n",
    "connections.connect(alias=\"default\")\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"job_ids\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=250),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "]\n",
    "schema = CollectionSchema(fields, \"APIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing\n",
    "job_description_emb= Collection(\"job_description_emb\", schema)\n",
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "job_description_emb.create_index(\"embeddings\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert embeddings\n",
    "sample_embeddings= np.load('sample_embeddings.npy')\n",
    "sample_data = pd.read_csv('cleaned_jobpostings_sample.csv')\n",
    "\n",
    "insert_data = [list(sample_data['Job Id']), sample_embeddings]\n",
    "job_description_emb.insert(insert_data)\n",
    "job_description_emb.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is just to control \n",
    "\n",
    "job_description_emb.load()\n",
    "search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 84}, \"offset\": 0}\n",
    "encodings = list(embeddings[:10])\n",
    "results = job_description_emb.search(\n",
    "    data=encodings, \n",
    "    anns_field=\"embeddings\", \n",
    "    param=search_params,\n",
    "    limit=2, \n",
    "    expr=None,\n",
    ")\n",
    "distances = [i.distances for i in results]\n",
    "job_ids = [i.ids for i in results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
